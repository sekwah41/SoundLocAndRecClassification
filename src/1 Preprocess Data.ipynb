{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modules needed\n",
    "## Preprocessing\n",
    " * install pandas\n",
    " * wavefile\n",
    " * matplotplib\n",
    " * LibROSA\n",
    " * numba==0.48.0\n",
    "## Machine learning\n",
    " * numpy\n",
    " * keras\n",
    " * sklearn\n",
    " * tensorflow\n",
    " * tqdm (just for fun)\n",
    "\n",
    "If you are using anaconda tensorflow should already be setup\n",
    "`pip install pandas wavefile matplotlib librosa numba==0.48.0 numpy keras sklearn tqdm keras tensorflow-gpu`\n",
    " \n",
    "## To enable progress bars\n",
    "`jupyter nbextension enable --py widgetsnbextension`\n",
    "`jupyter labextension install @jupyter-widgets/jupyterlab-manager`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join as join_path\n",
    "from wavefile import WaveReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performance Tweaking\n",
    "How many threads to use for multithreading and such.\n",
    "Some of the processing takes forever using default single threaded capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_threads = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "usl = \"../resources/UrbanSound8K/\"\n",
    "\n",
    "us_meta = pd.read_csv(usl + 'metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audio_data = []\n",
    "for i, entry in us_meta.iterrows():\n",
    "    file_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    with WaveReader(file_loc) as r:\n",
    "        # Probably easier way with this library to read the bit depth.\n",
    "        audio_data.append((r.channels, r.samplerate, int((r.byterate) / (r.samplerate * r.channels) * 8)))\n",
    "\n",
    "audio_df = pd.DataFrame(audio_data, columns=['num_channels', 'sample_rate', 'bit_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Summaries of Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels\n",
      "2    0.915369\n",
      "1    0.084631\n",
      "Name: num_channels, dtype: float64\n",
      "\n",
      "Sample Rates\n",
      "44100     0.614979\n",
      "48000     0.286532\n",
      "96000     0.069858\n",
      "24000     0.009391\n",
      "16000     0.005153\n",
      "22050     0.005039\n",
      "11025     0.004466\n",
      "192000    0.001947\n",
      "8000      0.001374\n",
      "11024     0.000802\n",
      "32000     0.000458\n",
      "Name: sample_rate, dtype: float64\n",
      "\n",
      "Bit Depth\n",
      "16    0.659414\n",
      "24    0.315277\n",
      "32    0.019354\n",
      "8     0.004924\n",
      "4     0.001031\n",
      "Name: bit_depth, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of channels\")\n",
    "print(audio_df.num_channels.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSample Rates\")\n",
    "print(audio_df.sample_rate.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nBit Depth\")\n",
    "print(audio_df.bit_depth.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preprocess files to be similar to the format being used in odas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "#import tqdm.notebook as tqdm\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name, e)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "\n",
    "def process_entry(file_entry):\n",
    "    i, entry = file_entry\n",
    "    entry_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    class_label = entry[\"class\"]\n",
    "    return [extract_features(entry_loc), class_label];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features: UrbanSound8K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8732/8732 [01:00<00:00, 144.87it/s]\n"
     ]
    }
   ],
   "source": [
    "urban_sound_features = []\n",
    "\n",
    "print(\"Extracting features: UrbanSound8K\")\n",
    "with Pool(max_threads) as p:\n",
    "    entries = us_meta.iterrows()\n",
    "    for value in tqdm.tqdm(p.imap(process_entry, entries), total=us_meta.shape[0]):\n",
    "        if value[1] != \"gun_shot\" and value[1] != \"dog_bark\":\n",
    "            urban_sound_features.append(value)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features: CustomSounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: fire_alarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 309/309 [00:01<00:00, 233.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 465.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: drilling\n",
      "No sounds found for: drilling\n",
      "Extracting: jackhammer\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "custom_sound_features = []\n",
    "custom_sound_loc = \"../resources/CustomSounds\"\n",
    "sound_class_folders = [f for f in listdir(custom_sound_loc) if isdir(join(custom_sound_loc, f))]\n",
    "# (fileLoc, class)test\n",
    "print(\"Extracting features: CustomSounds\")\n",
    "custom_sounds = []\n",
    "with Pool(max_threads) as p:\n",
    "    for class_name in sound_class_folders:\n",
    "        print(\"Extracting:\", class_name)\n",
    "        sound_files = [f for f in listdir(join(custom_sound_loc, class_name))\\\n",
    "                       if isfile(join(custom_sound_loc, class_name, f))]\n",
    "        if len(sound_files) == 0:\n",
    "            print(\"No sounds found for:\", class_name)\n",
    "            continue\n",
    "        file_locations = list(map(lambda f: join(custom_sound_loc, class_name, f), sound_files))\n",
    "        for value in tqdm.tqdm(p.imap(extract_features, file_locations), total=len(file_locations)):\n",
    "            custom_sound_features.append((value, class_name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8669  files\n",
      "Label Distribution\n",
      "jackhammer          0.115584\n",
      "children_playing    0.115354\n",
      "air_conditioner     0.115354\n",
      "street_music        0.115354\n",
      "drilling            0.115354\n",
      "dog_bark            0.115354\n",
      "engine_idling       0.115354\n",
      "siren               0.107163\n",
      "car_horn            0.049487\n",
      "fire_alarm          0.035644\n",
      "Name: class_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = urban_sound_features + custom_sound_features\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "print('Finished feature extraction from ', len(features_df), ' files')\n",
    "\n",
    "print(\"Label Distribution\")\n",
    "print(features_df.class_label.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prep learning and training dataset\n",
    "Will need to check at some point the 8k datasets because it does say something about don't randomise it or something.\n",
    "Though for now lets get to training! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(features_df.feature.tolist())\n",
    "y = np.array(features_df.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Store pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_train' (ndarray)\n",
      "Stored 'x_test' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n",
      "Stored 'yy' (ndarray)\n",
      "Stored 'le' (LabelEncoder)\n",
      "Stored 'X' (ndarray)\n",
      "Stored 'y' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "### Save values\n",
    "\n",
    "%store x_train \n",
    "%store x_test \n",
    "%store y_train \n",
    "%store y_test \n",
    "%store yy \n",
    "%store le\n",
    "%store X\n",
    "%store y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
