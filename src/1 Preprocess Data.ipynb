{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modules needed\n",
    "## Preprocessing\n",
    " * install pandas\n",
    " * wavefile\n",
    " * matplotplib\n",
    " * LibROSA\n",
    " * numba==0.48.0\n",
    "## Machine learning\n",
    " * numpy\n",
    " * keras\n",
    " * sklearn\n",
    " * tensorflow\n",
    " * tqdm (just for fun)\n",
    "\n",
    "If you are using anaconda tensorflow should already be setup\n",
    "`pip install pandas wavefile matplotlib librosa numba==0.48.0 numpy keras sklearn tqdm keras tensorflow-gpu`\n",
    " \n",
    "## To enable progress bars\n",
    "`jupyter nbextension enable --py widgetsnbextension`\n",
    "`jupyter labextension install @jupyter-widgets/jupyterlab-manager`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join as join_path\n",
    "from wavefile import WaveReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performance Tweaking\n",
    "How many threads to use for multithreading and such.\n",
    "Some of the processing takes forever using default single threaded capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_threads = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "usl = \"../resources/UrbanSound8K/\"\n",
    "\n",
    "us_meta = pd.read_csv(usl + 'metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audio_data = []\n",
    "for i, entry in us_meta.iterrows():\n",
    "    file_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    with WaveReader(file_loc) as r:\n",
    "        # Probably easier way with this library to read the bit depth.\n",
    "        audio_data.append((r.channels, r.samplerate, int((r.byterate) / (r.samplerate * r.channels) * 8)))\n",
    "\n",
    "audio_df = pd.DataFrame(audio_data, columns=['num_channels', 'sample_rate', 'bit_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Summaries of Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels\n",
      "2    0.915369\n",
      "1    0.084631\n",
      "Name: num_channels, dtype: float64\n",
      "\n",
      "Sample Rates\n",
      "44100     0.614979\n",
      "48000     0.286532\n",
      "96000     0.069858\n",
      "24000     0.009391\n",
      "16000     0.005153\n",
      "22050     0.005039\n",
      "11025     0.004466\n",
      "192000    0.001947\n",
      "8000      0.001374\n",
      "11024     0.000802\n",
      "32000     0.000458\n",
      "Name: sample_rate, dtype: float64\n",
      "\n",
      "Bit Depth\n",
      "16    0.659414\n",
      "24    0.315277\n",
      "32    0.019354\n",
      "8     0.004924\n",
      "4     0.001031\n",
      "Name: bit_depth, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of channels\")\n",
    "print(audio_df.num_channels.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSample Rates\")\n",
    "print(audio_df.sample_rate.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nBit Depth\")\n",
    "print(audio_df.bit_depth.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preprocess files to be similar to the format being used in odas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Extraction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015581a4ac67427990cf69eac254582c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8732.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished feature extraction from  8358  files\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import tqdm.notebook as tqdm\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name, e)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled\n",
    "\n",
    "def process_entry(file_entry):\n",
    "    i, entry = file_entry\n",
    "    entry_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    class_label = entry[\"class\"]\n",
    "    return [extract_features(entry_loc), class_label];\n",
    "\n",
    "features = []\n",
    "\n",
    "print(\"Starting Extraction\")\n",
    "with Pool(max_threads) as p:\n",
    "    entries = us_meta.iterrows()\n",
    "    for value in tqdm.tqdm(p.imap(process_entry, entries), total=us_meta.shape[0]):\n",
    "        if value[1] != \"gun_shot\":\n",
    "            features.append(value)\n",
    "        pass\n",
    "    \n",
    "\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(features_df), ' files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prep learning and training dataset\n",
    "Will need to check at some point the 8k datasets because it does say something about don't randomise it or something.\n",
    "Though for now lets get to training! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(features_df.feature.tolist())\n",
    "y = np.array(features_df.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Store pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_train' (ndarray)\n",
      "Stored 'x_test' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n",
      "Stored 'yy' (ndarray)\n",
      "Stored 'le' (LabelEncoder)\n"
     ]
    }
   ],
   "source": [
    "### Save values\n",
    "\n",
    "%store x_train \n",
    "%store x_test \n",
    "%store y_train \n",
    "%store y_test \n",
    "%store yy \n",
    "%store le\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
