{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modules needed\n",
    "## Preprocessing\n",
    " * install pandas\n",
    " * wavefile\n",
    " * matplotlib\n",
    " * LibROSA\n",
    " * numba==0.48.0\n",
    "## Machine learning\n",
    " * numpy\n",
    " * keras\n",
    " * sklearn\n",
    " * tensorflow\n",
    " * tqdm (just for fun)\n",
    "\n",
    "If you are using the docker contianer then you should just have to do this\n",
    "`pip install pandas wavefile matplotlib librosa numba==0.48.0 numpy keras sklearn tqdm keras`\n",
    " \n",
    "## To enable progress bars\n",
    "`jupyter nbextension enable --py widgetsnbextension`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join as join_path\n",
    "from wavefile import WaveReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performance Tweaking\n",
    "How many threads to use for multithreading and such.\n",
    "Some of the processing takes forever using default single threaded capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads: 24\n"
     ]
    }
   ],
   "source": [
    "max_threads = os.cpu_count()\n",
    "\n",
    "print(\"Threads: \" + str(max_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "usl = \"../resources/UrbanSound8K/\"\n",
    "\n",
    "us_meta = pd.read_csv(usl + 'metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100% 8732/8732 [00:43<00:00, 198.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "audio_data = []\n",
    "\n",
    "for i, entry in tqdm(us_meta.iterrows(), total=us_meta.shape[0], desc=\"Processing audio files\"):\n",
    "    file_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    with WaveReader(file_loc) as r:\n",
    "        bit_depth = int((r.byterate) / (r.samplerate * r.channels) * 8)\n",
    "        audio_data.append((r.channels, r.samplerate, bit_depth))\n",
    "\n",
    "audio_df = pd.DataFrame(audio_data, columns=['num_channels', 'sample_rate', 'bit_depth'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Summaries of Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels\n",
      "num_channels\n",
      "2    0.915369\n",
      "1    0.084631\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sample Rates\n",
      "sample_rate\n",
      "44100     0.614979\n",
      "48000     0.286532\n",
      "96000     0.069858\n",
      "24000     0.009391\n",
      "16000     0.005153\n",
      "22050     0.005039\n",
      "11025     0.004466\n",
      "192000    0.001947\n",
      "8000      0.001374\n",
      "11024     0.000802\n",
      "32000     0.000458\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Bit Depth\n",
      "bit_depth\n",
      "16    0.659414\n",
      "24    0.315277\n",
      "32    0.019354\n",
      "8     0.004924\n",
      "4     0.001031\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of channels\")\n",
    "print(audio_df.num_channels.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSample Rates\")\n",
    "print(audio_df.sample_rate.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nBit Depth\")\n",
    "print(audio_df.bit_depth.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preprocess files to be similar to the format being used in odas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "#import tqdm.notebook as tqdm\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "\n",
    "    # Load from processed file\n",
    "    if os.path.isfile(file_name + \".npy\"):\n",
    "        return np.load(file_name + \".npy\")\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name, e)\n",
    "        return None\n",
    "\n",
    "    np.save(file_name + \".npy\", mfccs)\n",
    "     \n",
    "    return mfccs\n",
    "\n",
    "def process_entry(file_entry):\n",
    "    i, entry = file_entry\n",
    "    entry_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    class_label = entry[\"class\"]\n",
    "    return [extract_features(entry_loc), class_label];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features: UrbanSound8K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 8732/8732 [00:08<00:00, 975.67it/s] \n"
     ]
    }
   ],
   "source": [
    "urban_sound_features = []\n",
    "\n",
    "print(\"Extracting features: UrbanSound8K\")\n",
    "with Pool(max_threads) as p:\n",
    "    entries = us_meta.iterrows()\n",
    "    for value in tqdm.tqdm(p.imap(process_entry, entries), total=us_meta.shape[0]):\n",
    "        if value[1] != \"gun_shot\":# and value[1] != \"dog_bark\":\n",
    "            urban_sound_features.append(value)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features: CustomSounds\n",
      "Extracting: KnockDetected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 55/55 [00:00<00:00, 1116.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: NoKnock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 191/191 [00:00<00:00, 1162.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "custom_sound_features = []\n",
    "custom_sound_loc = \"../resources/CustomSounds\"\n",
    "sound_class_folders = [f for f in listdir(custom_sound_loc) if isdir(join(custom_sound_loc, f))]\n",
    "# (fileLoc, class)test\n",
    "print(\"Extracting features: CustomSounds\")\n",
    "custom_sounds = []\n",
    "with Pool(max_threads) as p:\n",
    "    for class_name in sound_class_folders:\n",
    "        print(\"Extracting:\", class_name)\n",
    "        sound_files = [f for f in listdir(join(custom_sound_loc, class_name))\\\n",
    "                       if isfile(join(custom_sound_loc, class_name, f)) \n",
    "                       and not f.endswith(('.npy', '.DS_Store'))]\n",
    "        if len(sound_files) == 0:\n",
    "            print(\"No sounds found for:\", class_name)\n",
    "            continue\n",
    "        file_locations = list(map(lambda f: join(custom_sound_loc, class_name, f), sound_files))\n",
    "        for value in tqdm.tqdm(p.imap(extract_features, file_locations), total=len(file_locations)):\n",
    "            custom_sound_features.append((value, class_name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  8604  files\n",
      "Label Distribution\n",
      "class_label\n",
      "dog_bark            0.116225\n",
      "children_playing    0.116225\n",
      "air_conditioner     0.116225\n",
      "street_music        0.116225\n",
      "engine_idling       0.116225\n",
      "jackhammer          0.116225\n",
      "drilling            0.116225\n",
      "siren               0.107973\n",
      "car_horn            0.049861\n",
      "NoKnock             0.022199\n",
      "KnockDetected       0.006392\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = urban_sound_features + custom_sound_features\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "print('Finished feature extraction from ', len(features_df), ' files')\n",
    "\n",
    "print(\"Label Distribution\")\n",
    "print(features_df.class_label.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prep learning and training dataset\n",
    "Will need to check at some point the 8k datasets because it does say something about don't randomise it or something.\n",
    "Though for now lets get to training! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 21:33:01.842393: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(features_df.feature.tolist())\n",
    "y = np.array(features_df.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Store pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_train' (ndarray)\n",
      "Stored 'x_test' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n",
      "Stored 'yy' (ndarray)\n",
      "Stored 'le' (LabelEncoder)\n",
      "Stored 'X' (ndarray)\n",
      "Stored 'y' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "### Save values\n",
    "\n",
    "%store x_train \n",
    "%store x_test \n",
    "%store y_train \n",
    "%store y_test \n",
    "%store yy \n",
    "%store le\n",
    "%store X\n",
    "%store y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
