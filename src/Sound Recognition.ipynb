{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Modules needed\n",
    "## Preprocessing\n",
    " * pandas\n",
    " * wavefile\n",
    " * LibROSA\n",
    " * numba==0.48.0\n",
    " \n",
    "## Machine learning\n",
    " * numpy\n",
    " * keras\n",
    " * sklearn\n",
    " * tensorflow\n",
    " * tqdm (just for fun)\n",
    " \n",
    "## To enable progress bars\n",
    "`jupyter nbextension enable --py widgetsnbextension`\n",
    "`jupyter labextension install @jupyter-widgets/jupyterlab-manager`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join as join_path\n",
    "from wavefile import WaveReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "usl = \"../resources/UrbanSound8K/\"\n",
    "\n",
    "us_meta = pd.read_csv(usl + 'metadata/UrbanSound8K.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "audio_data = []\n",
    "for i, entry in us_meta.iterrows():\n",
    "    file_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    with WaveReader(file_loc) as r:\n",
    "        # Probably easier way with this library to read the bit depth.\n",
    "        audio_data.append((r.channels, r.samplerate, int((r.byterate) / (r.samplerate * r.channels) * 8)))\n",
    "\n",
    "audio_df = pd.DataFrame(audio_data, columns=['num_channels', 'sample_rate', 'bit_depth'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summaries of Sample Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number of channels\n",
      "2    0.915369\n",
      "1    0.084631\n",
      "Name: num_channels, dtype: float64\n",
      "\n",
      "Sample Rates\n",
      "44100     0.614979\n",
      "48000     0.286532\n",
      "96000     0.069858\n",
      "24000     0.009391\n",
      "16000     0.005153\n",
      "22050     0.005039\n",
      "11025     0.004466\n",
      "192000    0.001947\n",
      "8000      0.001374\n",
      "11024     0.000802\n",
      "32000     0.000458\n",
      "Name: sample_rate, dtype: float64\n",
      "\n",
      "Bit Depth\n",
      "16    0.659414\n",
      "24    0.315277\n",
      "32    0.019354\n",
      "8     0.004924\n",
      "4     0.001031\n",
      "Name: bit_depth, dtype: float64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Number of channels\")\n",
    "print(audio_df.num_channels.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSample Rates\")\n",
    "print(audio_df.sample_rate.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nBit Depth\")\n",
    "print(audio_df.bit_depth.value_counts(normalize=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess files to be similar to the format being used in odas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Starting Extraction\n",
      "Finished feature extraction from  0  files\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 8732/8732 [00:24<00:00, 350.63it/s]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import tqdm as tqdm\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name, e)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled\n",
    "\n",
    "def process_entry(file_entry):\n",
    "    file_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "    class_label = entry[\"class\"]\n",
    "    return [extract_features(file_loc), class_label];\n",
    "\n",
    "features = []\n",
    "\n",
    "print(\"Starting Extraction\")\n",
    "with Pool(12) as p:\n",
    "    entries = us_meta.iterrows()\n",
    "    for _ in tqdm.tqdm(p.imap(process_entry, entries), total=us_meta.shape[0]):\n",
    "        pass\n",
    "    #r = p.map(process_entry, entries)\n",
    "    #print(r)\n",
    "\n",
    "# for index, entry in tqdm.tqdm(us_meta.iterrows(), total=us_meta.shape[0]):\n",
    "#     file_loc = join_path(usl, \"audio\", 'fold' + str(entry[\"fold\"]), str(entry[\"slice_file_name\"]))\n",
    "#     class_label = entry[\"class\"]\n",
    "#     features.append(extract_features(file_loc))\n",
    "#     pass\n",
    "\n",
    "features_df = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(features_df), ' files')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prep for building model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
